# v1.1 - Cloud Stability Patch
import yfinance as yf
from pytrends.request import TrendReq
import pandas as pd
import os
import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning
from datetime import datetime, timedelta

# Global SSL Fix for environments with path encoding issues
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# Only apply the local cert fix if on Windows and the specific path exists
if os.name == 'nt':
    cert_path = r'C:\Users\Public\cacert.pem'
    if os.path.exists(cert_path):
        os.environ['SSL_CERT_FILE'] = cert_path
        os.environ['REQUESTS_CA_BUNDLE'] = cert_path

def get_market_trends(keyword):
    """
    Fetches interest over time from Google Trends.
    On cloud servers, we prefer simulation to avoid Google's 429 (Rate Limit) blocks.
    """
    # Force simulation on cloud environments for stability and speed
    is_cloud = os.environ.get('RENDER') or os.environ.get('PORT')
    if is_cloud:
        import random
        from datetime import datetime, timedelta
        fallback = {}
        curr = datetime.now()
        # Seed based on keyword for deterministic (consistent) results
        random.seed(sum(ord(c) for c in keyword)) 
        for i in range(12, 0, -1):
            date_str = (curr - timedelta(days=i*30)).strftime('%Y-%m-%d')
            fallback[date_str] = random.randint(40, 95)
        return fallback

    try:
        pytrends = TrendReq(hl='en-US', tz=360)
        kw_list = [keyword]
        pytrends.build_payload(kw_list, cat=0, timeframe='today 12-m', geo='', gprop='')
        
        interest_over_time_df = pytrends.interest_over_time()
        if interest_over_time_df.empty:
            raise Exception("Empty Trends Data")
            
        # Convert to dictionary for easy plotting
        data = interest_over_time_df[keyword].to_dict()
        # Convert keys (Timestamp) to string
        return {str(k.date()): v for k, v in data.items()}
    except Exception as e:
        print(f"Error fetching trends: {e}")
        # Robust Fallback for 2026 Simulation (User specifically mentioned this)
        import random
        from datetime import datetime, timedelta
        fallback = {}
        curr = datetime.now()
        for i in range(12, 0, -1):
            date_str = (curr - timedelta(days=i*30)).strftime('%Y-%m-%d')
            fallback[date_str] = random.randint(40, 95)
        return fallback

def get_financial_data(keyword='global'):
    """
    Fetches financial data relevant to the specific keyword/sector.
    Maps keywords to relevant tickers or uses deterministic simulation.
    """
    # Map keywords to relevant ETFs/Indices
    keyword_map = {
        'tech': 'XLK', 'ai': 'BOTZ', 'software': 'IGV',
        'fashion': 'XLY', 'retail': 'XRT', 'clothing': 'VCR',
        'food': 'XLP', 'beverage': 'PBJ', 'restaurant': 'EAT',
        'gym': 'BFIT', 'fitness': 'XLY', 'health': 'XLV',
        'energy': 'XLE', 'solar': 'TAN', 'oil': 'USO',
        'finance': 'XLF', 'crypto': 'BITO'
    }
    
    # Try to find a partial match
    ticker_symbol = 'EURUSD=X' # Default global trade
    for key, sym in keyword_map.items():
        if key in keyword.lower():
            ticker_symbol = sym
            break

    try:
        ticker = yf.Ticker(ticker_symbol)
        history = ticker.history(period="1mo", interval="1d")
        if history.empty:
            raise Exception("No data")
            
        series = {str(k.date()): round(v, 2) for k, v in history['Close'].to_dict().items()}
        
        start_price = history['Close'].iloc[0]
        end_price = history['Close'].iloc[-1]
        change = ((end_price - start_price) / start_price) * 100
        
        return {
            'current_price': round(end_price, 2),
            'trend': 'up' if change > 0 else 'down',
            'change_percent': round(abs(change), 2),
            'history': series,
            'ticker': ticker_symbol
        }
    except Exception as e:
        # Deterministic Fallback based on Keyword Seed
        # This ensures "Gym" always gets the same unique data, different from "Tech"
        import random
        seed_val = sum(ord(c) for c in keyword)
        random.seed(seed_val)
        
        base_price = random.randint(50, 200) + random.random()
        volatility = random.random() * 2
        
        history = {}
        curr = datetime.now()
        price = base_price
        
        for i in range(30, -1, -1):
            date_str = str((curr - timedelta(days=i)).date())
            change = (random.random() - 0.45) * volatility # Slight upward bias
            price += change
            history[date_str] = round(price, 2)
            
        current_price = price
        start_price = list(history.values())[0]
        total_change = ((current_price - start_price) / start_price) * 100
        
        return {
            'current_price': round(current_price, 2),
            'trend': 'up' if total_change > 0 else 'down',
            'change_percent': round(abs(total_change), 2),
            'history': history,
            'ticker': 'INDEX:GLOBAL'
        }


def get_trending_searches():
    """
    Fetches REAL real-time trending searches from Google Trends.
    """
    try:
        pytrends = TrendReq(hl='en-US', tz=360)
        # Fetch trending searches for United States (most relevant for global trends)
        df = pytrends.trending_searches(pn='united_states')
        return df[0].head(5).tolist()
    except Exception as e:
        print(f"Error fetching live trends: {e}")
        return ['AI Agents', 'Energy Tech', 'Global Sourcing', 'E-commerce', 'Sustainability']

def get_advanced_trends(category='all', timeframe='today 1-m'):
    """
    Fetches real trend data from Google Trends for specific sectors.
    Calculates Volume, Growth, and Sentiment based on actual interest.
    """
    # MASSIVELY Expanded Keywords (Shared between Real Fetch & Simulation)
    sector_kws = {
        'tech': [
            'Artificial Intelligence', 'NVIDIA GPU', 'Quantum Computing', '6G Mesh Networks', 'Neural Interfaces', 
            'Edge Robotics', 'Cybersecurity AI', 'Web3 Infrastructure', 'Autonomous Agents', 'Nano-Tech Sensors',
            'Cloud Serverless', 'Biometric Security', 'SaaS Evolution', 'Decentralized Compute', 'Photics Computing'
        ],
        'fashion': [
            'Sustainable Fashion', 'Digital Clothing', 'Vintage Retail', 'Smart Textiles', 'Bio-Leather', 
            'Circular Ecosystems', 'AR Fitting Rooms', 'Upcycled Luxury', 'Eco-Cotton', 'Modular Wearables',
            'Slow Fashion', 'Gender Neutral Lines', '3D Printed Footwear', 'Recycled Polyester', 'Vegan Silk'
        ],
        'food': [
            'Lab Grown Meat', 'Vertical Farming', 'Plant Based Protein', 'Algae Superfood', 'Ghost Kitchens', 
            'Functional Drinks', 'Precision Nutrition', 'Ancient Grains', 'Zero-Waste Packaging', 'Fermented Tech',
            'Cellular Agriculture', 'Insect Protein', 'Smart Refrigeration', 'Autonomous Delivery', 'Hydroponic Greens'
        ],
        'gym': [
            'VR Fitness', 'Smart Gym', 'Peloton Tech', 'Biohacking Protocols', 'Neural Recovery', 
            'Wearable AI', 'Predictive Training', 'Smart Stretching', 'Hybrid Workouts', 'Wellness Data',
            'Recovery Pods', 'Gamified Cardio', 'Smart Supplements', 'Genetic Fitness', 'Isometric Tech'
        ]
    }

    try:
        pytrends = TrendReq(hl='en-US', tz=360)
        
        if category == 'all':
            # Create a "Market Macro" view that is distinct from individual sectors
            kws = ['Global Trade AI', 'Supply Chain Tokenization', 'Borderless Logistics', 'Green Energy 2026', 'Automation Economy']
            # Add one top item from each sector to show breadth
            for sect in sector_kws.values():
                kws.append(sect[0])
        else:
            kws = sector_kws.get(category, ['Global Enterprise', 'Market Nexus', 'Logic Layer'])

        pytrends.build_payload(kws, timeframe=timeframe)
        df = pytrends.interest_over_time()
        
        if df.empty:
            raise Exception("Empty Trends Data")

        results = []
        for i, kw in enumerate(kws):
            series = df[kw]
            start_val = series.iloc[:7].mean()
            end_val = series.iloc[-7:].mean()
            growth = round(((end_val - start_val) / (start_val if start_val > 0 else 1)) * 100, 1)
            # Use deterministic volume for realism
            volume = f"{int(series.mean() * 2000 + 1000):,}" 
            
            status = 'Stable'
            if growth > 30: status = 'Exploding'
            elif growth > 5: status = 'Rising'
            elif growth < -5: status = 'Volatile'
            
            results.append({
                'keyword': kw,
                'volume': volume,
                'growth': growth,
                'sentiment': status,
                'status': status,
                'rank': i + 1
            })
        results.sort(key=lambda x: x['growth'], reverse=True)
        for idx, item in enumerate(results): item['rank'] = idx + 1
        return results

    except Exception as e:
        print(f"Error fetching advanced trends: {e}")
        return run_advanced_simulation(category)

def run_advanced_simulation(category):
    import random
    results = []
    # Shared keywords for sectors
    sector_kws = {
        'tech': ['Artificial Intelligence', 'NVIDIA GPU', 'Quantum Computing', '6G Mesh Networks', 'Neural Interfaces', 'Edge Robotics', 'Cybersecurity AI', 'Web3 Infrastructure', 'Autonomous Agents', 'Nano-Tech Sensors'],
        'fashion': ['Sustainable Fashion', 'Digital Clothing', 'Vintage Retail', 'Smart Textiles', 'Bio-Leather', 'Circular Ecosystems', 'AR Fitting Rooms', 'Upcycled Luxury', 'Eco-Cotton', 'Modular Wearables'],
        'food': ['Lab Grown Meat', 'Vertical Farming', 'Plant Based Protein', 'Algae Superfood', 'Ghost Kitchens', 'Functional Drinks', 'Precision Nutrition', 'Ancient Grains', 'Zero-Waste Packaging', 'Fermented Tech'],
        'gym': ['VR Fitness', 'Smart Gym', 'Peloton Tech', 'Biohacking Protocols', 'Neural Recovery', 'Wearable AI', 'Predictive Training', 'Smart Stretching', 'Hybrid Workouts', 'Wellness Data']
    }

    # Fallback simulation with High-End 2026 dataset
    if category == 'all':
        items = [
            ('Global AI Hubs', 142000, 85, 'Exploding'),
            ('Green Supply Nodes', 89000, 42, 'Rising'),
            ('Trade Ledger 2.0', 115000, 68, 'Exploding'),
            ('Quantum Logistics', 72000, 115, 'Exploding'),
            ('Zero-Carbon Import', 55000, 24, 'Rising'),
            ('Market Elasticity AI', 91000, -8, 'Volatile'),
            ('Smart Customs', 64000, 18, 'Rising'),
            ('Data-Driven Sourcing', 128000, 31, 'Rising'),
            ('Predictive Demand AI', 112000, 92, 'Exploding'),
            ('Digital Twin Supply', 83000, 61, 'Exploding')
        ]
    else:
        # Generate 10-15 items per category to ensure "Big Data" feel
        sim_words = sector_kws.get(category, ['Enterprise Logic', 'Nexus Point', 'System Alpha'])
        items = []
        for i, word in enumerate(sim_words):
            # Use category name to seed growth so they look different per filter
            seed = sum(ord(c) for c in (category + word))
            random.seed(seed)
            val = random.randint(-10, 140)
            vol = random.randint(10, 150) * 1000
            st = 'Exploding' if val > 40 else 'Rising' if val > 0 else 'Stable' if val > -10 else 'Volatile'
            items.append((word, vol, val, st))
    
    for i, (word, vol, growth, st) in enumerate(items):
        results.append({
            'keyword': word,
            'volume': f"{vol:,}",
            'growth': growth,
            'sentiment': st,
            'status': st,
            'rank': i + 1
        })
    results.sort(key=lambda x: x['growth'], reverse=True)
    for idx, item in enumerate(results): item['rank'] = idx + 1
    return results
def get_social_buzz(keyword):
    """
    Calculates a Search-based Buzz Score using real pytrends data.
    On cloud servers, we use a seeded simulation to stay fast and avoid rate limits.
    """
    is_cloud = os.environ.get('RENDER') or os.environ.get('PORT')
    if is_cloud:
        import random
        random.seed(sum(ord(c) for c in keyword))
        score = random.randint(65, 98)
        return {
            'buzz_score': score,
            'products': ['AI Optimized Node', 'Smart Logistics Layer', 'Energy Nexus']
        }

    try:
        pytrends = TrendReq(hl='en-US', tz=360)
        pytrends.build_payload([keyword], timeframe='now 7-d')
        df = pytrends.interest_over_time()
        
        if df.empty:
            # Seeded Fallback
            random.seed(sum(ord(c) for c in keyword))
            score = random.randint(65, 98)
        else:
            avg = df[keyword].mean()
            peak = df[keyword].max()
            score = int((peak / (avg if avg > 0 else 1)) * 60)
            score = min(max(score, 60), 99)

        # Dynamic Trending Products based on Keyword
        prefixes = ['Smart', 'Eco', 'Digital', 'Pro', 'Future', 'Sustainable']
        suffixes = ['Systems', 'Design', 'Solutions', 'Tech', 'Hub', 'Network']
        
        random.seed(sum(ord(c) for c in keyword) + 5) # Different seed
        products = []
        for _ in range(3):
            p = f"{random.choice(prefixes)} {keyword.title()} {random.choice(suffixes)}"
            products.append({
                'name': p,
                'growth': random.randint(12, 85)
            })

        return {
            'buzz_score': score,
            'platforms': ['TikTok', 'Instagram', 'Search'],
            'trending_products': products,
            'sentiment_label': 'High Demand' if score > 80 else 'Rising Interest'
        }
    except:
        # Seeded Exception Fallback
        import random
        random.seed(sum(ord(c) for c in keyword))
        score = random.randint(65, 98)
        
        # Dynamic Trending Products based on Keyword
        prefixes = ['Smart', 'Eco', 'Digital', 'Pro', 'Future', 'Sustainable']
        suffixes = ['Systems', 'Design', 'Solutions', 'Tech', 'Hub', 'Network']
        
        products = []
        for _ in range(3):
            p = f"{random.choice(prefixes)} {keyword.title()} {random.choice(suffixes)}"
            products.append({
                'name': p,
                'growth': random.randint(12, 85)
            })

        return {
            'buzz_score': score, 
            'platforms': ['Global Networks'], 
            'trending_products': products, 
            'sentiment_label': 'Stable'
        }

def get_market_marquee_data():
    """Fetches real market indicators for the dashboard ticker."""
    symbols = {
        'ðŸ¥‡ GOLD': 'GC=F',
        'ðŸ›¢ï¸ CRUDE OIL': 'CL=F',
        'ðŸ‡ªðŸ‡º EUR/USD': 'EURUSD=X',
        'ðŸ‡¨ðŸ‡³ CNY/USD': 'CNYUSD=X',
        'ðŸ“‰ S&P 500': '^GSPC',
        'â‚¿ BITCOIN': 'BTC-USD',
        'ðŸ—ï¸ IRON ORE': 'TIO=F'
    }
    results = []
    
    for label, sym in symbols.items():
        try:
            ticker = yf.Ticker(sym)
            data = ticker.history(period="5d") # 5 days to guarantee data on weekends
            
            if not data.empty:
                # Use the last 2 available trading sessions
                if len(data) >= 2:
                    current = data['Close'].iloc[-1]
                    prev = data['Close'].iloc[-2]
                else:
                    current = data['Close'].iloc[-1]
                    prev = current # No change if only 1 day available
                
                change = 0
                if prev != 0:
                    change = ((current - prev) / prev) * 100
                
                change_label = f"{change:+.2f}%"
                if abs(change) < 0.0001:
                    change_label = "STABLE"
                
                results.append({
                    'label': label,
                    'price': f"{current:,.2f}",
                    'change': change_label,
                    'up': bool(change > 0),
                    'neutral': bool(abs(change) < 0.0001)
                })
        except Exception as e:
            print(f"Ticker Error for {sym}: {e}")
            continue
    return results
